---
title: "coordinated_ordering13"
author: "GroupB"
date: "06/08/2020"
output:
  html_document:
    df_print: paged
    number_sections: no
    toc: yes
    toc_float: yes
    code_folding: "hide"
  pdf_document: default
  word_document:
    toc: yes
always_allow_html: true
---


```{r setup, include=FALSE, cache=F}
library(kableExtra)
library(knitr)
library(gtools)
```

# Introduction

Production planning is the process of determining a tentative plan for how much to produce in the next time period, during an interval of time called planning horizon. It is an important challenge for industrial companies because it has a strong impact on their performance in terms of customer service quality and operating costs.  Production planning often proves to be a very complex task because of several reasons, some of which are discussed below. One of the reasons is variability of products. A production resource is not only used for the production of one product, but to produce different types of products. The production resources available are limited and inflexible, as they can be used to produce only one type of product at a given time with a given production rate. Though the efficiency of a production resource is aimed to be maximised, it can still be used for a single product at a given time. The production planner thus needs to decide which products should be produced, when and in what quantities, while taking into account all the constraints in the system. Another reason is that a production plan might have to meet several conflicting objectives, for example, minimizing production and inventory costs while simultaneously increasing the productivity and the flexibility of production facilities and guaranteeing excellent customer service levels. 
One major planning decision is finding the economic lot size (production or order) which balances the inventory, ordering and set up costs. Deciding which materials are required to realise an aggregate production plan per period as well as determining how to properly bundle production lots in order to save ordering costs and stock up cost constitutes some of the most important operational activities of industrial companies.
Since the late 1940's, inventory theory has been one of the most successful operational research techniques to be applied in business, industry and the public sector (Goyal and Gupta, 1989). The very first lot size model was proposed by Ford Whitman Harris' in 1913 in his seminal paper entitled how many parts to make at once. In his paper, Harris proposed the Economic order Quantity model (EOQ) which enables the determination of optimum order quantities while avoiding excess inventory holding cost and shortage costs. Since its publications many variations have been made to this basic lot sizing problem including but not limited to: lot sizing models with dynamic or stationary demand, single or multiple level problems, single item or multiple item, capacitated or uncapacitated, deteriorating items, and deterministic or stochastic demand. Detailed description of these variations and more can be found in the papers by  Karimi et al. (2003) and Christoph H. et al.(2014). 
This paper aims to determine an optimal approach for coordinating the orders for a multi item capacitated lot sizing problem with deterministic demand. The reasoning here is that although the EOQ is optimal for the buyer, the buyer may stand to benefit from ordering more than the EOQ in situations where this leads to decreased transportation costs, administrative and handling costs as well as increased price discounts from suppliers. In this paper, a case study of a single storage unit of flow rack with multiple levels is explored where the demand for various materials is deterministic. The rest of this paper is structured as follows: a detailed description of the problem will be given in chapter 2, and the separate ordering and joint ordering solution approaches will be presented in chapter 3. Chapter 4 will expatiate on the assignment of lanes based on the cutting stock problem and chapter 5 will show an analysis of the overall results and concluding remarks. 

# Case Description

The given case describes an inbound warehouse where multiple materials are stored  in a storage facility.We are concerned with the storage facility which is the continuous flow rack.  A continuous flow rack is used to store small and medium sized parts.  There are a total of  8 racks, each flow rack consists of 4 levels and multiple runways or lanes per level. 

* *Materials and Boxes*

There are 62 materials in total and 9 types of boxes with varying dimensions. The materials are ordered and stored in boxes. There are different types of boxes, but each part is stored in one particular box type. Each box has a specific capacity for the number of items that can be stored in it. 

In each runway only one part should be stored. Thereby, the width of a runway can be adapted to the width of the box type which corresponds to the part assigned to the runway. Thus, the total number of runways per level depends on the assigned parts and is limited by the total width of the rack. 

* *Cost Distribution*

All parts are ordered from one supplier and only complete boxes can be ordered. The demand per day is given. Ordering of each box with a particular item incurs an ordering cost which is variable and dependent on the material ordered. A  fixed ordering cost of €1500 is incurred every time at least one order is placed. The stock holding cost  is based on the unit price and the interest rate. 

* *Task*

The aim of the project is to determine a lot sizing model that determines lot sizes for each part such that rack capacity constraints are adhered to and the total cost per period for stock holding and ordering are minimal.



# Data preparation 

Prior to analysing the data and formulating the models for the solution approaches, several manipulations were made to convert the data into a form that can be readily and accurately studied.

The following storage information is derived from the data sheets provided:

$Total_{racks}=8$,  $levels_{per_{rack}}=4$, $rack_{length}= 6000$, $rack_{width}=1750$, $rack_{height}=300$

| Total_racks | levels_per_rack | rack_length | rack_height |
|-----------|--------------|--------------|------------|
|Rack Information| 8 | 4 | 6000 | 1750 | 300 |

The following modifications were made to the data:

* *Product number (NO)*

Numbers were assigned to the materials ranging from 1 to 62 increasing order. The purpose of this is to make it easier to use and to refer to the products, rather than using their material IDs.


```{r,echo=FALSE}
library(readxl)

product_data <- read_excel("Data_ordering.xlsx",sheet = "product data")
box_data <- read_excel("Data_ordering.xlsx",sheet = "box data")
#rack data
Total_racks=8
levels_per_rack=4
rack_length= 6000
rack_width=1750
rack_height=300

init<- data.frame(Total_racks,levels_per_rack,rack_length,rack_width,rack_height)
colnames(init)<- c("Total_racks","levels_per_rack","rack_length","rack_width","rack_height")
rownames(init)<-"Rack Information"
kable(init,digits = c(1,1,1,1,1), caption= "Storage Information", format= "pandoc")
#product_data
product_data<-cbind(1:62,product_data)
colnames(product_data)<- c("N0", "material ID","demand per day","box ID","pieces/box","price")

kable(product_data[1:5,],format = "pandoc")
```


## Convert to Boxes

 From the data given, demand per item $d_i$, quantity ordered per item $q_i$, and the unit price per item $p_i$, are all converted in terms of boxes, using the capacity of the box for part $i$ , that is, $bc_i$

* The demand per item $d_i$ is converted to demand per box $y_i$ by dividing demand per item $d_i$ by the capacity of the box for part $i$ $bc_i$.

$$y_i=\frac {d_i*262}{bc_i} $$
* The demand per box is transformed to yearly demand by multiplying it by 262 days. We assumed that there are 262 working days for the year 2020 according to the Iowa Working Day Payroll Calendar. 
$y_i =$ demand per year

* The prices per item $p_i$ is converted into price per box $pr_i$ , by multiplying the price of the items by the number of items in each box.

$$pr_i= bc_i \cdot p_i$$


$pr_i = box\_cost=$ value of box



```{r,echo=FALSE}

product_data$demand_per_year= ceiling((product_data$`demand per day` *262)/ product_data$`pieces/box`) 

product_data$box_cost= product_data$`pieces/box`*product_data$price

#product_data



product_data <- merge(product_data, box_data[,c("box ID", "ordering cost (€)")], by = "box ID")

colnames(product_data)[9] <- "ordering_cost"


kable(product_data[1:5,c(1,2,3,8,9)],digits = c(1,1,1,1,1,1,1,1), caption= "Merged data with yearly demand", format= "pandoc")

#product_data<- product_data[,c("N0", "material ID","demand per day","box ID","pieces/box","price")]
#product_data

```


```{r,echo=FALSE}

product_data<- product_data[order(product_data$N0),]

row.names(product_data)<-1:62
kable(product_data[1:5,c(1,2,3,4,8,9)],format = "pandoc")


#product_data
```

# Solution Approaches
* *Notation*
The following notations were used while devising approaches.
$i \in I $ denote the set of parts considered, Total number of parts $i=62$

$d_i :$ demand per day for part $i$

$y_i :$ demand per year for part $i$, $d_i \cdot 262 $ days

$q_i :$ order quantity for part $i$

$p_i :$ unit price for part $i$

$bc_i :$ box capacity

$c^{-or} :$ fixed ordering cost

$c^{or}_i :$ variable ordering cost per box for part $i$

$c_i^{sh}=$ stock holding cost rate based on unit price $p_i$ and interest rate $h, \qquad$ therefore
$c_i^{sh}=pr_i \cdot h$


*Assumptions*


*1.* Every demand is fulfilled
*2.* Demand is deterministic
*3.* Lead time is zero
*4.* Waiting time is zero
*5.* There is limited storage capacity
*6.* Only complete boxes can be stored. In each runway, only one type of boxes are stored.



# Separate Ordering (SO)

In separate ordering, each box containing the unique material is ordered separately. Contrary to joint ordering, the orders are not batched together. Thus, each order incurs the fixed ordering cost of 1500 EUR in addition to the cost of holding and variable ordering cost.

The given case contains 62 different materials so in case of separate ordering, each of the materials are ordered separately. Thus 62 different order frequencies. 

The data about materials and their expected demand per day has been provided in the excel sheet “Product data.xlsx”.

Firstly, to determine how much to order (order quantity) and when to place order (the reorder point), we turned to the EOQ model. EOQ Model can be used in this case because the problem description matches with the assumptions in an EOQ model. The information for the case with respect to assumptions in the EOQ model is listed below.

*1.* Demand is uniformly distributed accross 262 days. In this case, the expected demands are given.

*2.* Whenever an order is placed, a fixed cost is incurred. For the case, the fixed cost is denoted by $c^{-or}$ which equals 1500 EUR.

*3.* Ordering cost for part $i$  is denoted by $c_i^{or}$. 

*4.* The stock holding cost $C_i^{sh}$ is based on the unit price $p_i$ and interest rate $h$, therefore it will cost $h \cdot p_i $  to stock one unit of that item.

*5. * The order arrives immediately after the placement of the order. 

*6. * All demand is satisfied on time.


## EOQ modelling

EOQ is calculated for each part i using the given formula which is denoted by Q* or Q max (Q max notation is used to differentiate it from Q min notation used in the later part) and minimum EOQ is calculated by omitting the fixed ordering cost $c^{-or}$ of 1500. This is done to find the starting feasible solution. 

calculate EOQ for each part i:

$$ q_i^{max} = \sqrt \frac{2 \cdot y_i \cdot (c_i^{or}+c^{-or})}{pr_i \cdot h}$$

Min EOQ, used in starting feasible solution.

$$ q_i^{min} = \sqrt \frac{2 \cdot y_i \cdot (c_i^{or})} {pr_i \cdot h}$$
$q_i^{max}== q^*$ these notations can be used interchangably both meaning Maximum EOQ.


Adding both EOQs,  “EOQ.max” and “EOQ.min” to the product_data table:


```{r,echo=FALSE}
#dei= demand_per_year, cori= ordering cost for box i
#cord= ordering cost, pri= box cost, h= interest rate

# directly vectorized
so_eoq_fun <- Vectorize(function(dei,cori,cord,pri,h){
  eoq<- sqrt((2*dei*(cori+cord))/(pri*h))
  return(eoq)
})

# maximum EOQ provided there is no coordination of ordering cycles (i.e., cord are not shared among parallely ordered items)
vec_so_eoq_fun.max <- so_eoq_fun(dei = product_data$demand_per_year,cori=product_data$ordering_cost,cord=1500,pri=product_data$box_cost,h=0.10)
# minimum EOQ disregarding common ordering cost cord
vec_so_eoq_fun.min <- so_eoq_fun(dei = product_data$demand_per_year,cori=product_data$ordering_cost,cord=0,pri=product_data$box_cost,h=0.10)

product_data$eoq.min <- round(vec_so_eoq_fun.min)
product_data$eoq.max <- round(vec_so_eoq_fun.max)
#product_data

kable(product_data[1:5,c(1,2,3,4,9,10,11)],digits = c(1,1,1,1,1,1,1,1), caption= "Both EOQs added to the table", format= "pandoc")

#product_data
```


## Lane Occupation

The Data pertaining to the boxes includes information regarding the way the boxes are sorted in the lanes. Two notations are derived from this information and added to the product_data Table, which are briefly discussed below.


$b_i$ = Box_sorting. This Represents how the box is sorted. Some boxes are sorted by width and others are sorted by length. If a box is sorted by width, this means the width of the runway is adapted to the width of the box type, when the box is assigned to the runway/lane. If a box is sorted by length, this means the width of the runway/lane is adapted to the length of the box type, when the box is assigned to the runway.


$b_i^{-1}$ = Box_not_sorting. This Represents the inverse of box sorting bi. If a box is sorted by width, then the box_not_sorting $b_i^{-1}$ is the length of the box. This value is used for the rack length calculations, to determine the number of boxes of a type and item, that can fit in one lane. In the same way, if a box is sorted by length, then the inverse is the width which is used in the rack length calculations.

The rack length is then used in combination with the Box_sorting and the Box_not_sorting to determine the  following; 




```{r,echo=FALSE}
# constraints #####################################
# this can be formulated more elegantly, but it works and that suffices
b_sorting <- double(length(product_data$`box ID`)) 
b_not_sorting <-double(length(product_data$`box ID`))

for(j in 1: length(box_data$`box ID`)){
  for (k in 1:length(product_data$`box ID`)) {
    if(box_data$`box ID`[j]==product_data$`box ID`[k]){
      
      if(box_data$sorting[j]=="width"){
        b_sorting[k] <- box_data$width[j]
        b_not_sorting[k]<- box_data$length[j]
        
      }else{
        b_sorting[k] <- box_data$length[j]
        b_not_sorting[k]<- box_data$width[j]
      }
    }
  }
  
}

product_data$b_sorting <- b_sorting 
product_data$b_not_sorting <- b_not_sorting
#product_data

kable(product_data[1:5,c(2,3,9:ncol(product_data))],digits = c(1,1,1,1,1,1,1,1), caption= "Both EOQs added to the table", format= "pandoc")

#product_data

```

E.g Using box_ID 6203060, sorted by length
$b_i=396$, $b_i^{-1}=297$
Also for material ID 7305667+74 with $q_i=180$ therefore,
$rack_{length}=6000$

*1.* Number of boxes in a lane:

$$n_i=\frac {rack_{length}}{b_i^{-1}}=\frac {6000}{297}=20.20=20boxes$$





*2.* How many lanes part $i$ will occupy if you order some number of boxes

$$lane_i=\frac {q_i}{n_i}$$ 
$$lane_i=q_i \cdot \frac {b_i^{-1}}{rack_{length}}=180 \cdot \frac {297}{6000}=8.91= 9 \space lanes $$

$$lane_i= \left\lceil\frac{b^{-1}_i \cdot q_i}{rl} \right \rceil$$

```{r,echo=FALSE}
lane <- ceiling(product_data$eoq.max * (product_data$b_not_sorting/rack_length))
laneso<- data.frame(rbind(lane))
rownames(laneso)<- "lanes"
colnames(laneso)<- 1:62
kable(laneso[1:8],format = "pandoc",caption = "number of lanes per item")
```

(C) Do we meet the capacity contraint?

*3.* Total number of lanes constraints

Collapsing Rack 4 levels in a rack and joining the 8 racks to become 1 level.

Total rack width available: 

$$rack_{total_{Width}}=(rack_{width} \times 4 \times 8)$$
Note: rack_total_width which is 56,000 mm, looking at the 9 patterns all of which have 150 mm in waste, meaning all 32 levels will have 150 mm waste each. Therefor $56,000−(150∗32)=51,200$ thereby changing rack total width 51,200.

These *9 patterns* will be explained later in the chapter.
```{r,echo=FALSE}
rack_total_width <-51200  #rack_width * 4 * 8
#rack_total_width #56000
```


```{r,echo=FALSE}
lane.min <- ceiling(product_data$eoq.min * product_data$b_not_sorting / rack_length)
#lane.min
lane.max <- ceiling(product_data$eoq.max * product_data$b_not_sorting / rack_length)

#lane.max

# total rack width 

rack_total_width <- 51200 # rack_width * 4 * 8

lane.df<- data.frame(rbind(lane.min,lane.max))
rownames(lane.df)<-c("Min lane","Max lane")
colnames(lane.df)<-1:62
kable(lane.df[,1:12],caption = "Number of lanes that minimizes cost",format = "pandoc")

#product_data
```



Min lane: This lanes was derived  from $q^{min}$.

Max lane: derived from $q^{max}$.


*  *Overflow*

This is how much we are lacking in capacity assuming we considered optimum lanes thus optimum quatities for all our items when placing an order.

- Overflow in mm

Expressing it in mm terms

$$\Bigg[ \sum_{i=1}^n lane_i \cdot b_i \Bigg]- rack_{{total}_{width}}$$
- relative overflow in %

In percentage terms

$$\frac{\big[\sum_{i=1}^n lane_i \cdot b_i \big]- rack_{{total}_{width}}} {rack_{{total}_{width}} } \cdot 100$$

```{r,echo=FALSE}
# overflow in mm
overflow.mm.lane.min<- sum(lane.min*product_data$b_sorting) - rack_total_width
overflow.mm.lane.max<-sum(lane.max*product_data$b_sorting) - rack_total_width
# relative overflow in %
overflow.per.lane.min<-(sum(lane.min*product_data$b_sorting) - rack_total_width)/rack_total_width*100
overflow.per.lane.max<- (sum(lane.max*product_data$b_sorting) - rack_total_width)/rack_total_width*100

overflow<- data.frame(overflow.mm.lane.min,overflow.mm.lane.max,overflow.per.lane.min,overflow.per.lane.max)

colnames(overflow)<-c("mm_lane_min","mm_lane_max","% lane_min","% lane.max")
rownames(overflow)<- "Overflow"

kable(overflow,caption = "Rack Capacity overflow in mm and percentage",format = "pandoc")

#product_data
```


*As seen above*, the capacity is exceeded by lots of margin even without adding  overall ordering capacity $c^{-or}$ it still exceeds by $427\%$


* *Introducing capacity constraint*

$$\sum_{i=1}^{n=62}lane_i \cdot b_i\le rack_{Total_{width}}$$ 
$$\sum_{i=1}^{n=62} q_i \cdot \frac {b_i^{-1} \cdot b_i}{rack_{length}} \le rack_{Total_{width}} \quad \quad (1)$$

```{r,echo=FALSE}
#get the width of the lanes in mm
rack_width_occupied=sum(lane.min*product_data$b_sorting)
kable(paste(rack_width_occupied,"mm"," is the total expected to be occupied"))

if(rack_width_occupied <= rack_total_width){
  print(paste0("Capacity constraint fulfilled: ", rack_width_occupied, "<=",rack_total_width))
 
}else {
  violated <- rack_width_occupied - rack_total_width
  kable((paste0("Capacity constraint violated by: ",violated )), format = "pandoc")
}


```
As seen above contraint was voilated by $218,694 mm$, thus we don't have that kind of capacity for that, therefore we need to optimize $q_i$ to fit our capacity.


Using our example to get number of the total width i.e (summation of lanes) in $mm$: 
Summation of lanes can simply be: 
$$lanes_i \cdot b_i= 8.91 \times 396=3528.36$$
Using equation (1) to prove this concept.

$$180 \cdot \frac {396 \cdot 297}{6000}=3528.36 $$
$$ b_i= \frac {3528.36}{8.91}=396$$

(D) Adjust Q by reducing it:

$\frac {y_i}{q_i}=$ number of orders for part $i$.

$\frac {q_i}{2}=$ average inventory for part $i$



## Constrained EOQ optimization

$$ min \rightarrow (62 \cdot c^{-or} + \sum_{i=1}^{n=62} \frac {y_i}{q_i} \cdot c_i^{or}) + (h \cdot \sum_{i=1}^{n=62} \frac {q_i}{2}\cdot pr_i ) $$
Subject to:
$$\sum_{i=1}^{n=62} q_i \cdot \frac {b_i^{-1} \cdot b_i}{rack_{length}} \le rack_{Total_{width}} $$



```{r,echo=FALSE}
library(ROI)
library(ROI.plugin.alabama)

n <- length(product_data$`material ID`) #number of materials
cori <- product_data$ordering_cost   #ordering cost for each items
cord <-  1500    #ordering cost whenever there is an order
dei <- product_data$demand_per_year
h<-0.10
box_cost <- product_data$box_cost #pri

# objective function --> I dropped the 1500*62 as it is not decision relevant
obj.fun <- function(q, d= dei, c.or = cori, c.h = h*box_cost  ) (1500*62)+(sum((dei/q)*c.or)+ sum(c.h*(q/2)))
# benchmarks
#obj.fun(product_data$eoq.max)
#obj.fun(product_data$eoq.min)
# constraint function --> also contains the ceiling of lanes and a sum was missing
const.fun <- function(q, bns = product_data$b_not_sorting, bs = product_data$b_sorting, rl = rack_length) {
  sum(bs * ceiling( bns * q / rl))
  }

#const.fun(product_data$eoq.max)
#const.fun(product_data$eoq.min)
# try to figure out a freasible starting solution
#const.fun(product_data$eoq.min/10) -  rack_total_width

obj.const<- data.frame(rbind(c(obj.fun(product_data$eoq.max),const.fun(product_data$eoq.max)),c(obj.fun(product_data$eoq.min),const.fun(product_data$eoq.min) )))

colnames(obj.const)<-c("Cost Function (€)", "Capacity in (mm)") 
rownames(obj.const)<-c("Eoq Max","Eoq Min")

kable(obj.const,caption = "Cost Values and capacities", format="pandoc")

```
As seen above, capcities of both EOQ's exceeds the our rack capacity of 56,000 mm.

Now adding capacity constraint

```{r,echo=FALSE}
qopt <- OP(
  objective = F_objective(F=obj.fun ,n=n),
  types = rep("C",n),
  bounds = V_bound(ub= product_data$eoq.min , lb= rep(1, n)),
  constraints = F_constraint(F=const.fun,
                             dir="<=",
                             rhs = rack_total_width)
)

#This shows that minimum EOQ is too big and therefore will not meet the rack space constraint.
#const.fun(min(product_data$eoq.max))#366272
#const.fun(min(product_data$eoq.max)/8)# 61428  still > 56000
#const.fun(min(product_data$eoq.max)/8.7)#52716 < 56000
#const.fun(min(product_data$eoq.max)/10)# 33098 < 56000 is much lower but this can still be the starting value
#round(min(product_data$eoq.max)/10) #15

```



```{r,echo=FALSE}
copt_sol <- ROI_solve(qopt, start = rep(min(product_data$eoq.max)/10,n), solver = "alabama" )
# always check whether the algorithm converged
#copt_sol# The objective value is: 101625.9
# solution
#copt_sol$solution #vector of optimal Quantity that meets the space constraints and minimizes the Obj function.
#round(copt_sol$solution)
#copt_sol$objval #101625.9



#const.fun(copt_sol$solution)#55884
#const.fun(floor(copt_sol$solution))#55092


#obj.fun(copt_sol$solution)#101625.9
#obj.fun(floor(copt_sol$solution))#104639.7  rounded q values

copt_solution<-data.frame(obj.fun(floor(copt_sol$solution)),rbind(floor(copt_sol$solution)))
colnames(copt_solution)<-c("cost",1:62)
rownames(copt_solution)< "constrained"

kable(copt_solution[,1:15],caption = "Capacitated values for cost and Quantity",format = "pandoc")

```


removing waste of 150 for every 32 levels

## No constraint

```{r,echo=FALSE}

rack_total_width <- 51200
qopt1 <- OP(
  objective = F_objective(F=obj.fun ,n=n),
  types = rep("C",n),
  bounds = V_bound(ub= product_data$eoq.min , lb= rep(1, n)),
)

copt_sol1 <- ROI_solve(qopt1, start = rep(min(product_data$eoq.max)/10,n), solver = "alabama" )
# always check whether the algorithm converged
#copt_sol1$objval
```




## Compare results



```{r,echo=FALSE}
#obj.fun <- function(q, d= dei, c.or = cori, c.h = h*box_cost  ) (1500*62)+(sum((dei/q)*c.or)+ sum(c.h*(q/2)))
#obj.fun(product_data$eoq.max)#172279.7
```



```{r,echo=FALSE}

#const.fun(copt_sol$solution)#51132
#const.fun(floor(copt_sol$solution))#50340  we rounded down to avoid exceeding capacity


#obj.fun(copt_sol$solution)#109279.9
#obj.fun(floor(copt_sol$solution))#112079.8 rounded q values

const.unconst <- data.frame(rbind(c(round(obj.fun(product_data$eoq.max)),round(const.fun(product_data$eoq.max))),c(round( obj.fun(copt_sol$solution)),round(const.fun(copt_sol$solution)))))
colnames(const.unconst)<-c("Cost Function (€)","capacitaty")
rownames(const.unconst)<-c("Eoq Max","Optimized Q")

kable(const.unconst,caption = "costs",format = "pandoc")

```

```{r,echo=FALSE}
#obj.fun(copt_sol1$solution)#124505.1
#obj.fun(floor(copt_sol1$solution))#124508.6 rounded q values

```


Optimum costs with no capacity constraint using EOQ.max considers is €172279.7, with no capacity constraint optimized using EOQ.min is €124508.6, with capacity constraint, it costs €205079.8 This cost is expected to be higher when capacity constraint is included, as limited capacity of the rack will not allow to take advantage of cost savings.

```{r,echo=FALSE}
# demand vs quantity

#product_data$`demand per day`
#product_data$demand_per_year  #


```


```{r,echo=FALSE}
#floor(copt_sol1$solution)#  optimum quantities with no capacity constraint same as eoq.min 
#floor(copt_sol$solution) # optimum quantities with capacity constraint
```

* Plot for lot sizes of costs EOQ Max vs Optimized for capacity

cost function per item
$$ C(q_i) \rightarrow (c^{-or} +  \frac {y_i}{q_i} \cdot c_i^{or}) + (h \cdot  \frac {q_i}{2}\cdot pr_i ) $$

```{r,echo=FALSE}
#EOQ cost

#with no constraint
#paste("with no capacity constraint, cost is  €", round(obj.fun(product_data$eoq.max)))#172280

#with no capacity constraint optimized.
#paste("with no capacity constraint optimized, cost is  €",round(obj.fun(copt_sol1$solution)))# eoq.min

#with constraint
#paste("with capacity constraint, cost is  €",round(obj.fun(copt_sol$solution))) #202280



kable(paste("It costs €",floor(obj.fun(floor(copt_sol$solution)))-floor(obj.fun(floor(product_data$eoq.max)))," extra due to lack of capacity"),format = "pandoc")

```
The above result shows that If there is no capacity constraint, the cost will be lower. 


```{r,echo=FALSE}
x.val <- seq.int(1,62, length.out = 62)

cost.fun <- function(q, d= dei, c.or = cori, c.h = h*box_cost  ){
  (1500 +(dei/q)*c.or)+ (c.h*(q/2))
} 

y.vec.no.const <- cost.fun(q=product_data$eoq.max)
y.vec.yes.const<- cost.fun(copt_sol$solution)

kable(paste(length(which((round(y.vec.yes.const)>=round(y.vec.no.const))==TRUE))," Items costs more or same when capacity becomes a problem"),format = "pandoc")


```

```{r,echo=FALSE}
#par(mfrow=c(1,1))
{ 
  plot(x.val,round(y.vec.no.const), xlab ="lot size q", ylab = "total cost", type = "p", lwd =2, ylim=c(12,max(y.vec.no.const)), xaxp=c(1, 10, 1) )
  axis(1, 1:62)
axis(2, 1:62)
abline(h=1:62, v=1:62, col="gray", lty=3)

points(x=x.val,y=round(y.vec.yes.const),lwd=2, col="blue")

legend("bottomleft",lty = c(1,1),col = c("black","blue"), legend = c("No constraint","with constraint"), bty="n" , horiz = T)
}


```

* Notice that 26 blue dots which represents the more expensive items when capacity is accounted for.

* Also the notice , for most items where the blue is larger than black (non constraint items)(the variance is much more) the difference is much larger. the reverse is the case when black is larger than blue.


# Joint Ordering (JO)

*Joint replenishment problem with no Capacity Constraints*

Joint replenishment problem focuses on how to coordinate the order of multiple items, from the same supplier. This problem is one which is very similar to the general Lot sizing problem with the only difference being that, rather than having the same machine, we have the same supplier.Here we shall consider a group of items which should be replenished jointly as much as possible (Axsäter, 2006).
 When placing a purchase order for multiple items, the cost component can be divided into the fixed cost, which is independent of the products being purchased and the variable costs which depends on the purchased items (Goyal 1974). If multiple products are ordered at the same time, the general ordering cost (fixed cost) will have to be paid once. This leads to a reduction in costs. The buyer could also benefit from quantity discounts offered by suppliers when large batch sizes are ordered. Through coordination, transportation cost can be reduced as well.
 Because of the major ordering cost, using group replenishment may lead to substantial cost savings. The savings from group replenishment are more significant the higher the major ordering cost (Khouja and Goyal, 2008). Joint replenishment therefore aims to determine the optimum ordering frequency which will minimise ordering and holding costs. So, the focus here is on the cycle time; ordering as many products as possible in a cycle. 


Assumptions:

- One supplier with outbound storage.
- $i=\{1,...,n\}$ products
- Demand rates for part $i$: $de_i$
- Stock_holding cost rates for part $i$: $c_i^{sh}$
- Specific ordering costs for part $i$: $c_i^{or}$
- General ordering costs: $c^{-or}$
- Cycle time of product $i$: $T_i$


```{r,echo=FALSE}
n <- length(product_data$`box ID`)
c.or0 <- cord
c.or <- product_data$ordering_cost
#H.vec <- 0.5 * dei * c.sh
# based on the previous definition, I think this should be the vector of holding cost multipliers
H.vec <- 0.1 * product_data$box_cost * dei * 0.5
```


## Objective Function with no capacity constraint

- $B=$basic cycle time
- $H_i=0.5 \cdot y_i \cdot c_i^{sh}$
- $H_0=0$  Holding cost multiplier are $H_0 \space and  \space H_i$
- $$C(m_i B)=\sum_{i=0}^n (\frac {c_i^{or}}{m_i \cdot B}+H_i \cdot m_i \cdot B) == \frac {c_o^{or}}{B}+ \sum_{i=1}^n (\frac {c_i^{or}}{m_i \cdot B}+H_i \cdot m_i \cdot B)$$
 subject  to: 
 $$\quad \quad \quad \quad \quad \quad \quad \quad \quad
  m_i \ge m_0 \quad \forall i >0 $$
  
  $$m_i \in \mathbb N \qquad \forall i   $$

--> an important side note is that the JRP is basically a quite standard EOQ problem which uses the substitution $T_i = \frac{q_i}{y_i}$, i.e., $q_i = T_i \cdot y_i$. Then, you substitute $T_i = m_i \cdot B$ ans result in the JRP (adding the common ordering cost).

```{r,echo=FALSE}
jrp.obj.fun <- function(m , B, cor, Hvec, cor0) cor0/B + sum(cor/B/m) + sum(Hvec*B*m)
```



- *Cycle Time*

we determine $T_i=\sqrt (\frac {c_i^{or}}{H_i})$ and $T^C=\frac {\sum_{j=0}^{i´} c_j^{or}}{\sum_{j=0}^{i´}H_j}$
```{r,echo=FALSE}
# calculate cycle times
T.vec <- sqrt(c.or/H.vec)
# order products
reo.id <- order(T.vec)
T.vec <- T.vec[reo.id]
c.or <- c.or[reo.id]
H.vec <- H.vec[reo.id]

cost_cycle.mat <- t(cbind(c.or,H.vec,T.vec))
costs.cycle <- data.frame(cost_cycle.mat)
colnames(costs.cycle) <- reo.id 
rownames(costs.cycle) <- c(  "$c_i^{or}$" ,"$H_i$","$T_i$" )
kable(costs.cycle[,1:4],"pandoc", row.names = T)
```


```{r,echo=FALSE}
library(kableExtra)
# calculate T^2 and cumu. cost shares
res.mat <- t(cbind(c.or/H.vec,(c.or0 + cumsum(c.or))/cumsum(H.vec)))
df <- data.frame(res.mat)
colnames(df) <- reo.id 
rownames(df) <- c(  "$T_i^2$" ,"$T^C$"  )
kable(df[,1:4],"pandoc", row.names = T)#%>%
  #scroll_box(width = "100%", height = "200px")

```


$$B=\sqrt \frac {\sum_{i=0}^n \frac {c_i^{or}}{m_i}}{\sum_{i=0}^n m_i \cdot H_i} $$


```{r,echo=FALSE}
# identify break
which(res.mat[1,] > res.mat[2,])# break occured after 13
id.comb <- min(which(res.mat[1,] > res.mat[2,])) - 1 #3
#id.comb
# calculate B
B <- min(T.vec) #0.01955164
# solution with m - integers #######################
m.vec.int <- round(T.vec/B,0)

m.vec.int[1:id.comb] <- 1  
# re-optimize B for fixed m.vec
B.int <- sqrt(sum(c.or/m.vec.int)/sum(m.vec.int*H.vec))#0.02014868
# total cost 
c.cost.int <- jrp.obj.fun( m = m.vec.int, B=B.int, cor = c.or,Hvec=H.vec, cor0 = c.or0)#192606
df <- data.frame(rbind(round(T.vec/B.int,2), round(T.vec/B.int), m.vec.int))
colnames(df) <- reo.id 

rownames(df) <- c("$m_i= {T_i}/{B}$" ,"$[m_i]$", "$[\\tilde{m}_i]$" )
kable(df[,1:6],"pandoc", row.names = T)
```


break occured after 13

Reoptimizing basic cycle time yields $B=$  $`r round(B.int,2)`$ and the total cost are `r round(c.cost.int,2)` 

The order quantities are given by multiplying the cycle times $T_i$ with demand rates $y_i$, i.e. $q_i = T_i \cdot y_i$ such that

```{r,echo=FALSE}
dei <- dei[reo.id]
df <- data.frame(rbind( m.vec.int, round(m.vec.int*B.int, 2), round(m.vec.int*B.int*dei, 2) ))
colnames(df) <- reo.id 
rownames(df) <- c("$[\\tilde{m}_i]$", "$T_i$", "$q_i$" )
kable(df[,1:6],"pandoc", row.names = T)
```

--> Now the question is: Is this feasible? --> no:

```{r,echo=FALSE}
q.vec <- m.vec.int*B.int*dei
#paste(round(c.cost.int)," is total cost with no capacity constraint")# 49943
#const.fun(q.vec) > rack_total_width

jrp.no_cap <- data.frame(round(c.cost.int),const.fun(q.vec))

colnames(jrp.no_cap)<-c("Cost(€)","Capacity (mm)")
rownames(jrp.no_cap)<-"Not constrained"

kable(jrp.no_cap,digit=c(1,1),caption = "cost with no capacity constraint", format = "pandoc")

```





Though  there is alot of cost savings, but the capacity required to meet this cost far exceeds the current capacity on ground.

When you try to optimize the JRP directly, without introducing the substitution $T_i = m_i \cdot B$ you need to update the JRP function as follows

$$C(T)=\sum_{i=0}^n (\frac {c_i^{or}}{T}+H_i \cdot T) == \sum_{i=1}^n \frac {c_o^{or}}{T}+ \sum_{i=1}^n (\frac {c_i^{or}}{T}+H_i \cdot T) $$

```{r,echo=FALSE}
library(ROI)
jrp.obj.fun2 <- function(Tvec, cor, Hvec, cor0) sum(cor0/Tvec) + sum(cor/Tvec) + sum(Hvec*Tvec)
# you need to initialize the parameters in the objective function --> Tvec is to be optimized over, the rest is given
jrp.obj.fun2 <- function(Tvec, cor=c.or, Hvec = H.vec, cor0 = c.or0) sum(cor0/Tvec) + sum(cor/Tvec) + sum(Hvec*Tvec)

qopt2 <- OP(
  objective = F_objective(F=jrp.obj.fun2 , n=62),
  types = rep("C",n),
  bounds = V_bound(ub= rep(30, 62), lb= rep(.001,62))
) 

#jrp.obj.fun2(m.vec.int*B)
#jrp.obj.fun2(rep(.00001,62))
#jrp.obj.fun2(rep(15,62))
# you don't need Alabama here as there is no constraint. Basically you can also optimize this problem by taking derivatives
copt_sol2 <- ROI_solve(qopt2, start = m.vec.int*B)
#copt_sol2

#copt_sol2$solution


jrp.no_cap.cycleTime <- data.frame(round(copt_sol2$objval),const.fun(copt_sol2$solution*dei))

colnames(jrp.no_cap.cycleTime)<-c("Cost(€)","Capacity (mm)")
rownames(jrp.no_cap.cycleTime)<-"Not constrained"

kable(jrp.no_cap.cycleTime,digit=c(1,1),caption = "cost with no capacity constraint using cycle Time", format = "pandoc")

```




Compared to the previous solution, this is far more inefficient.As It costs more and also required more capacity.
```{r,echo=FALSE}
#m.vec.int*B*dei

#paste(round(copt_sol2$objval), "Total cost with no Constraint for T")
```


## Including capacity constraint



--> You should  integrate the shelf capacity constraint while still using basic period approach as it so far has the lowest cost when not constrained.

This is formally defined as 
$$ \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot q_i}{rl} \right \rceil \leq \text{tot_rack_length}$$
Thus, with the substitution above, the left-hand side changes to
$$ \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot T_i \cdot y_i}{rl} \right \rceil = \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot m_i \cdot B \cdot y_i}{rl} \right \rceil$$



Thus, you can change the constraint function quite easily

```{r,echo=FALSE}

# we reinitialize the vectors
n <- length(product_data$`box ID`)
c.or0 <- cord
c.or <- product_data$ordering_cost
dei <- product_data$demand_per_year
H.vec <- 0.1 * product_data$box_cost * dei * 0.5


bnotsort <- product_data$b_not_sorting
bsort <- product_data$b_sorting
copt_sol.solution <- copt_sol$solution



# calculate cycle times
T.vec <- sqrt(c.or/H.vec)
# order products
reo.id <- order(T.vec)
T.vec <- T.vec[reo.id]
c.or <- c.or[reo.id]
H.vec <- H.vec[reo.id]
bnotsort <- bnotsort[reo.id]
bsort <- bsort[reo.id]
copt_sol.solution <- copt_sol.solution[reo.id]
dei <- dei[reo.id]

const.fun2 <- function(m, B = B.start, y= dei, bns = bnotsort, bs = bsort, rl = rack_length) {
  sum(bs * ceiling( bns * m*B*y / rl))
  }
```

Then, you can use the original JRP function and update the model by including the capacity constraint. Therefore I recommend that you fix $B$ to some appropriate value based on the feasible solution above

$rack_{Totalwidth}=51200$

```{r,echo=FALSE}

#rack_total_width<-51200

#library(ROI.plugin.deoptim)

T.feas <- copt_sol.solution/dei
B.start <- min(T.feas)

jrp.obj.fun <- function(m , B = B.start, cor = c.or, Hvec = H.vec, cor0 = c.or0) cor0/B + sum(cor/B/m) + sum(Hvec*B*m)
#jrp.obj.fun(m= rep(1, 62))
#const.fun2(m= rep(1, 62))

qopt3 <- OP(
  objective = F_objective(F=jrp.obj.fun ,n=n),
  # now integer decision variables
  types = rep("C",n),
  bounds = V_bound(li = 1:n, ui = 1:n, ub= rep(50, n) , lb= rep(1, n)),
  constraints = F_constraint(F=const.fun2,
                             dir="<=",
                             rhs = rack_total_width)
)
# Good starting point essential --> m = T.feas/B.start
copt_sol3 <- ROI_solve(qopt3, start = T.feas/B.start , solver = "alabama")  # "deoptimr"

#copt_sol3

#copt_sol3$solution

#jrp.obj.fun(m= copt_sol3$solution)
#const.fun2(m= copt_sol3$solution) <= rack_total_width

jrp.cap.m <- data.frame(round(copt_sol3$objval),const.fun2(m= copt_sol3$solution))

colnames(jrp.cap.m)<-c("Cost(€)","Capacity (mm)")
rownames(jrp.cap.m)<-"Capacitated"

kable(jrp.cap.m,digit=c(1,1),caption = "cost with capacity constraint using Basic period approach", format = "pandoc")

```
Though more expensive, this met the capacity.

```{r,echo=FALSE}
# not feasible
#const.fun2(round(copt_sol3$solution)) <= rack_total_width
# feasible
#const.fun2(floor(copt_sol3$solution)) <= rack_total_width
# potential starting solution
m.start <- floor(copt_sol3$solution) # multiplier m
q.start <- ceiling(m.start * B.start * dei)   # order quantity q (in boxes, rounded up)
#q.start

```


```{r,echo=FALSE}
#Order according to m in ascending order
#reo.id <- order(m.start)
#dei <- dei[reo.id]
#m.start <- m.start[reo.id]

df2 <- data.frame(rbind( m.start, round(m.start*B.start, 2), ceiling(m.start*B.start*dei) ))
colnames(df2) <- reo.id 
rownames(df2) <- c("$[\\tilde{m}_i]$", "$T_i$", "$q_i$" )
kable(df2[,1:6],caption = "First 7 items in order before reordering","pandoc", row.names = T)
```


```{r,echo=FALSE}
library(gtools)
df2<-df2[mixedorder(colnames(df2))]
```


```{r,echo=FALSE}
kable(df2[,1:6],caption = "First 7 items in order After reordering","pandoc", row.names = T)
```

* *Order by m*
```{r,echo=FALSE}
#t(df2[order(row.names(df2[1,])), ])
#df2[order(product_data[1,]),]
#df2[order(rownames(df2))]
#df2

#sort(t(df2[1,]))
```


```{r,echo=FALSE}

q.start<- as.vector(df2[3,1:62])


kable(q.start[,1:9],caption = "After reordering","pandoc", row.names = T)
```


find a layout scheme such that a precise shelf layout results.

calculate the number of lanes $l(q_i)$ required for each product given a certain order quantity $q_i$ (integer number of boxes):

$$l(q_i) =\left\lceil \frac{q_i}{n_i} \right\rceil$$
whereby $n_i$ is the number of boxes per lane dedicated to product $i$. I.e., $$n_i = \left\lfloor \frac{rl}{b_i^{-1}} \right\rfloor$$. Thus, for the solution of the JRP we have:

```{r,echo=FALSE}
l.start <- ceiling(q.start/floor(rack_length/product_data$b_not_sorting))
rownames(l.start) <- "lanes"


kable(l.start[,1:10],caption = "number of lanes for each items ", row.names = T,format = "pandoc")
```



Now, these lanes have to be assigned to the levels of the shelves. Therefore, we first need to determine the types of lanes required. The lanes are just described by their width. Due to the safety margins we should round the lane width to full centimeter. I.e., we need to assign lanes with the following widths,$200mm, 400mm$ and $600mm$

```{r,echo=FALSE}
#unique(round(product_data$b_sorting/100)*100)
```
Now comes the tricky part: We have to decide how many lanes of a certain width should be assigned for each level. Luckily, there is only a small number of useful patterns of lanes per level. To be precise there are 9 efficient patterns to arrange these 3 lane types (assuming we use each level exhaustively):

```{r,echo=FALSE}
patterns <- rbind(
c(8,0,0),
c(0,4,0),
c(0,1,2),
c(2,0,2),
c(6,1,0),
c(4,2,0),
c(2,3,0),
c(3,1,1),
c(1,2,1)
)
colnames(patterns) <- c("200","400","600")



kable(as.data.frame(patterns) ,caption = "Total of 9 patterns ", row.names = T,format = "pandoc")

```


Let $p_{k,j}$ indicate the number of lanes of type $j$ associated to pattern $k$. Now we need to assess the number of lanes per required of each type. As outlined above, we know the number of lanes per product $l(q_i)$, thus we can deduce the demand for lane type $j$ ($ld_j$) by summing up the $l(q_i)$  for each lane type,  i.e., $ld_j = \sum_{i \in P|b_i=j} l(q_i)$:

```{r,echo=FALSE}
# assign lane width as names
names(l.start) <- round(product_data$b_sorting/100)*100 

# number of items with lane types 200, 400, 600 that is demand for each lane type
ld <- c(sum(l.start[names(l.start) == "200"]),
sum(l.start[names(l.start) == "400"]),
sum(l.start[names(l.start) == "600"]))
ld <-data.frame(rbind(t(ld)))
colnames(ld)<-c("200","400","600")

vec<-unlist(l.start)

product_data$number_of_lanes <- vec


kable(ld ,caption = "number of lanes per required of each type", row.names = T,format = "pandoc")
#ld
```
This misfit was due to approximations in the on lane assignment by making fraction value to ceiling.

Need to reduce 70 units to 64 for type 600.

reduce lane assignment while fulfilling demand, to do this, we need to change some values to their floor values. but this can cause backorder, that is inability to meet demand.

```{r,echo=FALSE}
tmp<- q.start/floor(rack_length/product_data$b_not_sorting)
rownames(tmp)<- "l(qi)"
kable(as.data.frame(rbind(tmp[1:6])),format = "pandoc",caption = "lanes in fraction")
```

To reduce the effect of  backorder, as seen above, items 15, 17, 18, 50,57 and 58 are closest decimals to there floor.
```{r,echo=FALSE}
tmp<-as.data.frame(rbind(tmp))
kable(tmp[,c(15,17,18,50,57,58)],format = "pandoc",caption = "selected items")
```

$l.start[15]=1$ , $l.start[17]=1$ , $l.start[18]=1$ , $l.start[50]=1$ ,$l.start[57]=2$, $l.start[58]=2$


```{r,echo=FALSE}
#cycle_demand== Lot_size_q
#cycle_demand <- product_data$cycle_time_in_days*product_data$deman_per_day_boxes

#l.start2 <- (cycle_demand *product_data$b_not_sorting)/rack_length
#l.start2 <- ceiling(l.start)
l.start[15]<-1
l.start[17]<- 1
l.start[18]<-1
l.start[50]<- 1
l.start[57]<- 2
l.start[58]<-2

#l.start2 <- ceiling(l.start)
vec<-unlist(l.start)

product_data$number_of_lanes <- vec


kable(product_data[c(15,17,18,50,57,58),c(2,3,12:ncol(product_data))],format = "pandoc")

#product_data


```

```{r,echo=FALSE}
# assign lane width as names
names(l.start) <- round(product_data$b_sorting/100)*100 

# number of items with lane types 200, 400, 600 that is demand for each lane type
ld <- c(sum(l.start[names(l.start) == "200"]),
sum(l.start[names(l.start) == "400"]),
sum(l.start[names(l.start) == "600"]))
kable(as.data.frame(ld),format = "pandoc",caption = "Number of lanes for 200, 400 and 600")
```





* *Changes made for lane assignment*


1. rack_total_width which was  56,000 mm, looking at the 9 patterns all of which have 150 mm in waste, meaning  all 32 levels will have 150 mm waste each. Therefor $56,000 - (150 *32) = 51,200$ thereby changing rack total width 51,200.

2. These changes then affects the values of q  for all the 62 items involved.





```{r,echo=FALSE}
pat<-data.frame(patterns[3:4,]) 
colnames(pat)<-c("200","400","600")

kable(pat,caption = "Patterns needed", row.names = T, escape = F,format = "pandoc")
```




* *Assign Patterns*

```{r,echo=FALSE}

fitted.pattern <- patterns[3:4,]
# loop through 32 levels to assign patterns

levels.pattern.mat <- matrix(0,  nrow = 33,ncol = 3)

for (i in 1:32) {
  for (j in 1:3) {
    
  if(i<= 16){
    levels.pattern.mat[i,j] <- t(fitted.pattern[1,j])
  } else {
     levels.pattern.mat[i,j] <- t(fitted.pattern[2,j])
   }
  }
}




levels.pattern.mat<-data.frame(rbind(levels.pattern.mat)) 
colnames(levels.pattern.mat)<-c("200","400","600")
levels.pattern.mat[33,]<-rbind(sum(levels.pattern.mat[1:32,1]),sum(levels.pattern.mat[1:32,2]),sum(levels.pattern.mat[1:32,3]))
rownames(levels.pattern.mat)<-c(1:32,"sum")
kable(levels.pattern.mat,caption = "Pattern Assigned for each level", row.names = T, escape = F,format = "pandoc")

# confirm if lane demand is met.

#sum(levels.pattern.mat[1:32,1]) >= sum(ld[1]) #TRUE  for 200
#sum(levels.pattern.mat[1:32,2]) >= sum(ld[2]) #TRUE  for 400
#sum(levels.pattern.mat[1:32,3]) >= sum(ld[3]) #TRUE  for 600



```



* *Assign Items to racks*




## Illustration

```{r,echo=FALSE}

#m.start

product_data$Order_frequency_M<- unlist(df2[1,1:62])
product_data$Lot_size_q <- unlist(q.start)
#product_data

#m.start <- sort(unique(product_data$Order_frequency_M))
m.start <- product_data$Order_frequency_M
#sort(unique(m.start)) # 21 unique values meaning 22 columns

#max(m.start)

name.m<- paste("Mi=",sort(unique(m.start)), sep = "")

cycle.mat <- matrix(0,  nrow = max(m.start)+1,ncol = length(unique(m.start)))

colnames(cycle.mat)<-name.m

#cycle.mat
# for first row
i<- NULL
j<-1


  for(i in sort(unique(m.start))){
  
      tmp <- which(m.start==i)
      tmp<- paste(tmp,collapse = ",")
      
      cycle.mat[1,name.m[j]] <- tmp
      j<- j+1
      
    }
 


for (k in 1:max(m.start)+1) {
  j<- 1
  for(i in sort(unique(m.start))){
    if((k-1)%%i==0){
      tmp <- which(m.start==i)
      tmp<- paste(tmp,collapse = ",")
      
      #print(tmp)
      
      cycle.mat[k,name.m[j]] <- tmp
      j<- j+1 
    }else {
      j<- j+1  
    }
     
  }
  
  }

cycle.df <- as.data.frame(cycle.mat)  
#cycle.df

rownames(cycle.df)<-1:nrow(cycle.df)

#[1:6,1:3]
kable(cycle.df, row.names = T, format = "pandoc")
```



Items in Mi=1 has 32 order frequency, While Mi=2 has 16 order frequencies in 
```{r,echo=FALSE}
#paste("We have ", ncol(cycle.df)," Order frequencies using Joint Ordering JRP")
```



display Item 4 , having lotsize of 19


```{r,echo=FALSE}

kable(product_data[4,10:ncol(product_data)],caption = "item 4", format = "pandoc")


```
*  *Demand vs Quantity*

$bc_i$ which is the capacity of a box for part $i$. 
$y_i=$ Demand in Years for item $i$
$yb_i=$ Demand per day in boxes for item $i$.
$yd_i=$ Demand per day in items for item $i$
$yb_i= \frac {yd_i}{bc_i} $

$ct =$cycle time is number of days it takes before a new order.

E.g Item 4 has lot size quantity of 19 boxes, and daily demand in boxes is 1.8
$$ct=  \bigg \lfloor \frac {q}{yb_i}\bigg \rfloor= \bigg \lfloor \frac  {m_i \cdot B \cdot y_i}{yb_i}\bigg \rfloor$$

$$ct=\bigg \lfloor \frac {4 \cdot 0.009435516 \cdot 492}{1.875}\bigg \rfloor=9.9= 9days $$
item 4 has order frequency M of 4, and is value is 9.9 then floor value is 9

* *Explain formular for demand per day in boxes*
```{r,echo=FALSE}
# Demand per day in boxes
#its still okay to leave the values in fraction as we are not ordering now.
product_data$deman_per_day_boxes <- product_data$`demand per day`/product_data$`pieces/box`

#This is number of days it takes before a new order "product_data$Lot_size_q" is placed
product_data$cycle_time_in_days <- (m.start*B.start*product_data$demand_per_year)/product_data$deman_per_day_boxes
#product_data$cycle_time_in_days

kable(product_data[4,14:ncol(product_data)],caption = "item 4", format = "pandoc")
```

As seen above, cycle time in days in 9.9 days, but  we need to round this to the nearest floor
```{r,echo=FALSE}
cyc<- as.data.frame(rbind(product_data$Order_frequency_M,product_data$cycle_time_in_days))
colnames(cyc)<-1:62
rownames(cyc)<-c("M","days")
#[,1:4]
kable(cyc,caption = "cycle time for each item", format = "pandoc")
```

give them floor values

```{r,echo=FALSE}
product_data$cycle_time_in_days<-floor(product_data$cycle_time_in_days)

cyc<- as.data.frame(rbind(product_data$Order_frequency_M,product_data$cycle_time_in_days))
colnames(cyc)<-1:62
rownames(cyc)<-c("M","days")
kable(cyc,caption = "cycle time for each item", format = "pandoc")
```


*  *Convert Cycles to days*
```{r,echo=FALSE}
#min(product_data$cycle_time_in_days)#2.472104 days is equivalent to M=1
#sort(sort(unique(product_data$Order_frequency_M)))
#sort(unique(product_data$Order_frequency_M))*min(product_data$cycle_time_in_days)

cycle.time.frac <-(m.start*B.start*product_data$demand_per_year)/product_data$deman_per_day_boxes

cycle.time <- data.frame(rbind(sort(unique(product_data$Order_frequency_M))*min(cycle.time.frac)   ))

colnames(cycle.time) <- sort(unique(product_data$Order_frequency_M))
rownames(cycle.time) <- c("Days M." )

kable(round(cycle.time,2), format = "pandoc")
```



*  *Prove that demand is always met*


Using (T,S) policy

We are using periodic review as order intervals can be derived from order frequency $m$ for each of the $i^{th}$ items. 


* $y_t=$ Assuming demand is uniformly distributed thus the same quantity of demand repeats each time.

* $S=$ Initial stock level for the 62 items are given based on lanes assigned

* $T=$ Each Item has some form of order frequency $m$ which we derived cycle time $ct$ from, going over a time period of 262 days. This represents order interval.

* $L$ Lead time is zero.

* At each order interval, we order up to $S$ which is the stock level based on lane assigned for each item meaning, lanes are filled.

* Backorder is allowed but customers are willing to wait

* Stock is filled to the capacity in period 1.



*Notations and Formulars*

On-hand stock S(t)

Outstanding orders O(t)

Backorders B(t)

Inventory level $I_t= I_{t-1}-y_t$ available units


In the code below, Shows (T,S) Policy, how demand is met over 262 time period.
Reason for TS policy is that we can not exceed capacity, thus we order upto Lane capacity of each item. Also each item has its cycle time in days which was derived from order frequency M.



$$S_i=\bigg \lfloor \frac {lanes_i \cdot rl}{b_i^{-1}} \bigg \rfloor $$
$S$ is the stock level, gotten from lane assigned to each items, the floor of stock level ensures that complete boxes are assigned to a lane.
e.g

```{r,echo=FALSE}
#names(product_data)
#product_data

kable(product_data[4,c("material ID","box ID","number_of_lanes","b_not_sorting")],format = "pandoc")
```
using item 4 as an example again

$$S_2=\bigg \lfloor \frac {2 \cdot 6000}{396} \bigg \rfloor =30.30 =30boxes$$
That is 30 boxes in 2 lanes as a lane contains 15 boxes of item 4
```{r,echo=FALSE}
#install.packages("writexl")
#library("writexl")

#write_xlsx(product_data,"C:\\Users\\aduzo\\Desktop\\Scientific Project R\\Scientific Project Main\\Decision-Support-for-Operations-Management-Issues\\product_data.xlsx")

stock.level <- floor((product_data$number_of_lanes*rack_length)/product_data$b_not_sorting)

#product_data$number_of_lanes
#floor(stock.level)
stock.level<- data.frame(rbind(floor(stock.level)))
colnames(stock.level)<-1:62
rownames(stock.level)<- "Stock level"

kable(stock.level[,1:10],caption = "Stock level derived from lanes assigned per item", format = "pandoc")

stock.level<-floor(unlist(stock.level))
```

```{r,echo=FALSE}
Periodic.inventory <-function(item){
  
  #Yt demand
dem <- product_data$deman_per_day_boxes
#dem[item]

#qt quantity
quant <- product_data$Lot_size_q
#quant[item]

#Initial Stock level
stock.level <- floor((product_data$number_of_lanes*rack_length)/product_data$b_not_sorting)
#stock.level[item]

#inventory level
#inventory.level <- inventory.level[t-1]- dem[t]

period.mat <- matrix(0.00000,  nrow = 3,ncol = 262)

colnames(period.mat)<-1:262
m <- product_data$cycle_time_in_days

#period.mat[3,0]<-  stock.level[1]
t<- 1
#for (t in 1:262) {
while(t<=262){
    
    
    if(t==1){
    period.mat[1,t]<-dem[item]
    period.mat[2,t]<- stock.level[item]
    period.mat[3,t]<- stock.level[item]-dem[item] #stock.level[1]
    
  }else {
    period.mat[1,t]<-dem[item]
    if(t %% floor(m[item])==1){
      #b<-t+1
      #print(t+1)
     period.mat[2,t]<- quant[item]
     
     # fill the capacity
     period.mat[3,t]<- stock.level[item] #quant[item]+period.mat[3,t-1]-dem[item]
    }else{
     period.mat[2,t]<- 0
      period.mat[3,t]<- period.mat[3,t-1]-dem[item]
    }
  }
  
  
#}

 t=t+1
    
  }
  
  
  return (period.mat)
  
}

period.df <- as.data.frame(Periodic.inventory(4))
row.names(period.df)<- c("yt","qt","lt")

#[,1:11]
kable(period.df,caption = "Periodic Inventory TS Policy", row.names = T, escape = F,format = "pandoc")
```





.
Alpha service level is the probability of no stockout per order cycle.
deriving alpha service level from the TS policy table,

$$\frac{\sum_{t=1}^{262}  l_t}{262} $$
$ l_t >= 0$

```{r,echo=FALSE}
Ave.phy.inv <-c(vector(),1:62)
alpha.sl <- c(vector(),1:62)
for (i in 1:62) {
  period.df <- as.data.frame(Periodic.inventory(i))
  row.names(period.df)<- c("yt","qt","lt")
  Ave.phy.inv[i]<- sum(period.df[3,][period.df[3,]>0])/length(period.df[3,])
  alpha.sl[i] <- (length(period.df[3,][period.df[3,]>=0])/length(period.df[3,])) *100
}

ts.summary <- data.frame(rbind(Ave.phy.inv,alpha.sl))

colnames(ts.summary)<- 1:62
rownames(ts.summary)<-c("Average Inventory","Alpha Service Level")

#[,c(1,17,18,50)]
kable(ts.summary,caption = "Periodic Inventory TS Policy",format = "pandoc")

```


As seen from the result, only Items 17 and 18 has an $\alpha$ service level of 90.458% and item 50 has $\alpha$ service level of 99.618321% and the rest of the items has 100% $\alpha$ service level.

make there service level be 100% by ordering earlier.

```{r,echo=FALSE}
names(product_data)
kable(product_data[c(17,18,50),c("deman_per_day_boxes","Order_frequency_M","cycle_time_in_days")],format = "pandoc")
```

Demand occurs in occurs for items not in boxes as order are done in boxes thus we store in boxes, so  0.4 is good this means the boxes are not filled.

cycle times for items 17 and 18 where assigned 37days, while that of items 50 is 15 days from 7days

```{r,echo=FALSE}
product_data$cycle_time_in_days[c(17,18)]<-37
product_data$cycle_time_in_days[c(50)]<-15
```



```{r,echo=FALSE}

Ave.phy.inv <-c(vector(),1:62)
alpha.sl <- c(vector(),1:62)
for (i in 1:62) {
  period.df <- as.data.frame(Periodic.inventory(i))
  row.names(period.df)<- c("yt","qt","lt")
  Ave.phy.inv[i]<- sum(period.df[3,][period.df[3,]>0])/length(period.df[3,])
  alpha.sl[i] <- (length(period.df[3,][period.df[3,]>0])/length(period.df[3,])) *100
}

ts.summary <- data.frame(rbind(Ave.phy.inv,alpha.sl))

colnames(ts.summary)<- 1:62
rownames(ts.summary)<-c("Average Inventory","Alpha Service Level")

#[,1:4]

kable(ts.summary[,c(1,17,18,50)],caption = "Periodic Inventory TS Policy",format = "pandoc")

```


```{r,echo=FALSE}

period.df <- as.data.frame(Periodic.inventory(50))
row.names(period.df)<- c("yt","qt","lt")


kable(period.df[,1:7],caption = "Periodic Inventory TS Policy", row.names = T, escape = F,format = "pandoc")
```


```{r,echo=FALSE}

#period.df[3,]
item <- 4
par(family="serif", mar = c(4.25,4.25,.1,.1), bg ="white")
{plot(Periodic.inventory(item)[3,], xlab="Time", type="l", lwd=2, ylab="demand", cex.lab = 1.5, cex.axis = 1.25)
abline(h=stock.level[item], col="red", lwd=2)
title(main=paste("item ",item),outer = TRUE)}

```
Using Item 4 as an example, $S=30$ depicted by the red horizontal line, as seen, demand is always met across 262 working days.


## Using S,Q Policy 

From Illustration table, Using S,Q policy and Applying JRP. We are lowering the safety stock

If this where to be sq policy, we only order when the quantity is zero.

Asumption:

* Stock level was derived from lanes assigned to each item.

* $i_t= min(Stock_level,order_quantity) - d_i$ 

Check if Lot size q is less than or equal to Stock level

```{r}
j<- 0
k<-0
for(i in 1:62){
  if(product_data$Lot_size_q[i]<= stock.level[i]){
    j<-j+1
    k<-k+1
  }else{
    j<-j+1
    
    print(paste("item ", j," Stock level greater Lot size"))
  }
}

paste(k," items have Quantity less than or equal to capacity")
```



Since 58 items has Lot sizes less than than or equal to lane capacity allocated, this means that in 4 items the lot size quantities is greater than capacity. 

This is to ensure that amount ordered is can be contained in the capacity. as 

```{r,echo=FALSE}
continous.inventory <-function(item){
  
  #Yt demand
dem <- product_data$deman_per_day_boxes
#dem[item]

#qt quantity
quant <- product_data$Lot_size_q
#quant[item]

#Initial Stock level
stock.level <- floor((product_data$number_of_lanes*rack_length)/product_data$b_not_sorting)
#stock.level[item]

#inventory level
#inventory.level <- inventory.level[t-1]- dem[t]

continous.mat <- matrix(0.00000,  nrow = 3,ncol = 262)

colnames(continous.mat)<-1:262
m <- product_data$cycle_time_in_days

#period.mat[3,0]<-  stock.level[1]
t<- 1
#for (t in 1:262) {
while(t<=262){
    if(product_data$Lot_size_q[i]<= stock.level[i]){
      
          if(t==1){
    continous.mat[1,t]<-dem[item]
    continous.mat[2,t]<- quant[item]
    continous.mat[3,t]<- quant[item]-dem[item] #stock.level[1]
    
  }else {
    continous.mat[1,t]<-dem[item]
    if(t %% floor(m[item])==1){
      #b<-t+1
      #print(t+1)
     
     
     
     if(continous.mat[3,t-1]>= continous.mat[1,t-1]){
       continous.mat[2,t]<- quant[item]
     }else{
       continous.mat[2,t]<- quant[item]-(continous.mat[1,t-1]-continous.mat[3,t-1])
     }
     continous.mat[3,t]<- quant[item]-dem[item] #period.mat[3,t-1] + quant[item]-dem[item]
    }else{
     continous.mat[2,t]<- 0
      continous.mat[3,t]<- continous.mat[3,t-1]-dem[item]
    }
  }
    
      
    }else {
        
      
      
          if(t==1){
    continous.mat[1,t]<-dem[item]
    continous.mat[2,t]<- stock.level[item]
    continous.mat[3,t]<- stock.level[item]-dem[item] #stock.level[1]
    
  }else {
    continous.mat[1,t]<-dem[item]
    if(t %% floor(m[item])==1){
      #b<-t+1
      #print(t+1)
      if(continous.mat[3,t-1]>= continous.mat[1,t-1]){
       continous.mat[2,t]<- quant[item]
     }else{
       continous.mat[2,t]<- quant[item]-(continous.mat[1,t-1]-continous.mat[3,t-1])
     }
     # fill the capacity
     continous.mat[3,t]<- stock.level[item]-dem[item] #period.mat[3,t-1] + quant[item]-dem[item]
    }else{
     continous.mat[2,t]<- 0
      continous.mat[3,t]<- continous.mat[3,t-1]-dem[item]
    }
  }
      
      
      }
    

  
  
#}

 t=t+1
    
  }
  
  
  return (continous.mat)
  
}

item<- 4
continous.df <- as.data.frame(continous.inventory(item))
row.names(period.df)<- c("yt","qt","lt")

#[,1:11]
kable(continous.df[,1:20],caption = paste("Continous Review Inventory  Policy item",item), row.names = T, escape = F,format = "pandoc")
```



### Service Level

```{r,echo=FALSE}
Ave.phy.inv <-c(vector(),1:62)
alpha.sl <- c(vector(),1:62)
for (i in 1:62) {
  continous.df <- as.data.frame(continous.inventory(i))
  row.names(continous.df)<- c("yt","qt","lt")
  Ave.phy.inv[i]<- sum(continous.df[3,][continous.df[3,]>0])/length(continous.df[3,])
  alpha.sl[i] <- (length(continous.df[3,][continous.df[3,]>0])/length(continous.df[3,])) *100
}

sq.summary <- data.frame(rbind(Ave.phy.inv,alpha.sl))

colnames(sq.summary)<- 1:62
rownames(sq.summary)<-c("Average Inventory","Alpha Service Level")

#[,1:4]
kable(sq.summary[,6],caption = "Continous Inventory SQ Policy",format = "pandoc")
```


```{r,echo=FALSE}
item <- 4
par(family="serif", mar = c(4.25,4.25,.1,.1), bg ="white")
{plot(continous.inventory(item)[3,], xlab="Time", type="l", lwd=2, ylab="demand", cex.lab = 1.5, cex.axis = 1.25)
abline(h=product_data$Lot_size_q[item]%% product_data$deman_per_day_boxes[item], col="red", lwd=2)
title(main=paste("item ",item),outer = TRUE)}
```

The table above is Item 1 cycle

Reordering points of this policy is near zero

* Cycle time in days  vs Order frequency m 

```{r,echo=FALSE}
kable(round(cycle.time,2), format = "pandoc")
```

Item 1 has M value of 24 meaning 59 days as cycle time in day, this means therefore, how many cycles in a year(262) meaning total of 4 cycles this can be seen from the diagram its also 4 cycles.



cycle time 
```{r}
product_data$cycle_time_in_days[1]

product_data$Order_frequency_M
```


# Analysis

## ABC Analysis

Inventory systems are used to supply subsequent processes with material required to carry out these processes. These processes could be production processes or Customer service, etc. Materials are therefore a necessary evil, held and managed in order to enable other processes. The goal of every organisation therefore is to implement a material provisioning concept, which strives to minimise inventory necessary to provide other services .
The characteristics of the materials determines the most appropriate provisioning concepts to be implemented. The problem case in this study uses a storage warehouse provisioning concept. To better understand the characteristics of the materials in this study, we categorise the products by Value, using the ABC analysis. This is because when we talk about stock level and inventory systems related cost, the value of the material is one of the most important drivers. The higher the value, the more costs are implied due to the opportunity cost involved in holding stock.in other words the higher the value the more we should focus on material minimisation
As enumerated in the OVGU Inventory management Lecture slides for the ST 2020 by Prof. Dr. T. Kirschstein, the following steps are used to categorize the material by value 


Procedure:
$d_i=$consumption and $p_i=$ price of material $i \in I$, then
1. Calculate value share of material $i:v_i=\frac {d_i\cdot p_i}{\sum_{j\in I}d_j \cdot p_j}$

```{r,echo=FALSE}
#remember box cost is demand times price
value.share <- product_data$box_cost/sum(product_data$box_cost)
#as.data.frame(value.share)  
#value.share
```

2. Order materials descendingly according to value share: $v_1^´ \ge v_2^´ \ge...\ge v_{|I|}^´$

$v_i^´=ord.share$
```{r,echo=FALSE}
#cycle.time <- data.frame(rbind(sort(unique(product_data$Order_frequency_M))*min(product_data$cycle_time_in_days)   ))

#colnames(cycle.time) <- sort(unique(product_data$Order_frequency_M))
#rownames(cycle.time) <- c("Days M." )

#kable(cycle.time,"html", row.names = T, escape = F) %>%
#  kable_styling("striped")



#ord.share<- data.frame(rbind(sort(value.share,decreasing=TRUE) )) 
#reoder.item <- order(value.share,decreasing = TRUE)
#colnames(ord.share)<- reoder.item 
#ord.share
#as.data.frame(ord.share)

id.vec <- 1:62

#id.vec.ord contains the indexes of materials in decreasing order.
id.vec.ord <- id.vec[order(value.share, decreasing = T)]

#val.vec.ord contains values of the materials in decreasing order
val.vec.ord <- sort(value.share,decreasing = T)

```



3. Calculate cumulative ordered value share of each material: $\tilde v_i= \sum_{j=1}^i v_j^´$ 

$\tilde v_i= cum.val.vec.ord$
```{r,echo=FALSE}
cum.val.vec.ord <-cumsum(val.vec.ord)
rel.cum.val.vec.ord <- cum.val.vec.ord / sum(val.vec.ord)

#rel.cum.val.vec.ord
```

4. Categorize materials according to $\tilde v_i$ into classes A,B and C by class limits e.g 80,95,100.

The results of the categorization are summarized in the table below, for the first 3 materials of every class. The full table can be found in the appended R script 

```{r,echo=FALSE}
class.vec <- rep("A", n)
class.vec[rel.cum.val.vec.ord > 0.8 & rel.cum.val.vec.ord <= 0.95 ] <- "B"
class.vec[rel.cum.val.vec.ord > 0.95 ] <- "C"

tab <- data.frame("ord.material.id" = id.vec.ord, "price (ord.)" = product_data$box_cost[order(value.share, decreasing = T)] , "demand (ord.)" = product_data$deman_per_day_boxes[order(value.share, decreasing = T)], "mat.values" = val.vec.ord, "cum.mat.values" = cum.val.vec.ord, "rel.cum.value.shares" = round(rel.cum.val.vec.ord * 100, 1), "class" = class.vec )

kable(tab, digits = c(0,2,0,2,2,1,0),  caption = "ABC analysis results (values classified by boxes)", format = "pandoc")
```

A visual representation of the results is also shown in the graph below.

```{r,echo=FALSE}
# a plot
plot(1:n, rel.cum.val.vec.ord, type="b", xaxt = "n", pch =16, xlab = "material id", ylab = "rel. cum. value share")
axis(1, at = 1:n, labels = id.vec.ord)
abline(h = c(.8,.95), lwd=2, lty=2, col="darkgrey")
text(x = rep(1,3) , y = c(.5,.875,.99), labels = LETTERS[1:3] )
```


From the graph above, we can see that although there are lots of materials with low values (Class A), the number of high valued materials (Class B and C) is quite significant. Given that these materials are all kept in inventory, there is a need to develop an optimal inventory planning system, such that the costs involved in holding these stocks in inventory will be minimised as much as possible while also ensuring that all demand is fulfilled  . The next section of this report gives an overview of such a model.






## Cost Analysis

```{r,echo=FALSE}
#with no constraint
##paste("Seperate Ordering with no capacity constraint, cost is  €", round(obj.fun(product_data$eoq.max)))#172280

#with no capacity constraint optimized.
#paste("Seperate Ordering with no capacity constraint optimized, cost is  €",round(obj.fun(copt_sol1$solution)))# eoq.min

#with constraint
##paste("Seperate Ordering with capacity constraint, cost is  €",round(obj.fun(copt_sol$solution))) #202280

#JRP

##paste("Joint Ordering with no capacity constraint, cost is  €",round(c.cost.int)," for m")# € 49943


##paste("Joint Ordering with no capacity constraint, cost is  €",round(copt_sol2$objval)," for T")# € 49943


##paste("Joint Ordering with capacity constraint, cost is  €",round(copt_sol3$objval)," for m")# € 49943


cost.matrix <- data.frame("unconstrained"=c(round(obj.fun(product_data$eoq.max)),round(c.cost.int)),
                      "constrained"=c(round(obj.fun(copt_sol$solution)),round(copt_sol3$objval)))
rownames(cost.matrix)=c("Separate Ordering","Joint Ordering")

kable(cost.matrix,digits = c(0,1,1,1),caption = "Total cost Matrix", row.names = T, escape = F,format = "pandoc")
  
```


in the matrix above, it costs more to When capacity is an issue for both seperate Ordering and Joint Ordering. When non capacited ordering, there is far more cost savings than Separate ordering.

```{r,echo=FALSE}
#?seq.int
#Seperate ordering sequence
k<- 0
for (j in 1:62) {
  if(round(product_data$eoq.max[j])>round(copt_sol$solution[j])){
    k<-k+1
    
  }
}

#print(k)
```

The eoq value for the 62 items are greater than optimized values.


creating a matrix of length  40 filling it with sequence of order quantity values from eoq to optimized order quantity 
```{r,echo=FALSE}
so.mat<- matrix(0,nrow = 62, ncol = 40)

for (i in 1:62) {
  
  so.mat[i,]<- seq.int(round(product_data$eoq.max[i]),round(copt_sol$solution[i]) ,length.out = 40)

}

so.mat.df<-data.frame("Items"=1:62,rbind(so.mat))
rownames(so.mat.df)<-paste("part",1:62)
colnames(so.mat.df)<-c("Items",1:40)

kable(so.mat.df[1:5,1:6],caption = "Items and samples",format = "pandoc")


```

* *Separate Ordering*



```{r,echo=FALSE}
#quant.no.const <- data.frame(rbind(round(q.vec )))
#colnames(quant.no.const) <- reo.id 
#rownames(quant.no.const) <- c("$q_i$")
#kable(quant.no.const[,1:10],"pandoc", row.names = T)


#library(gtools)
#quant.no.const<-quant.no.const[mixedorder(colnames(quant.no.const))]
#quant.no.const
# higher cost arranged
#q.start

#length(which((quant.no.const > q.start)== TRUE))# 61
#which((quant.no.const < q.start)== TRUE)# only 57

#quant.no.const[57]

#q.start[57]

so.df <- data.frame(rbind(round(product_data$eoq.max,0),floor(copt_sol$solution)))

so.df <-cbind(sum=c(sum(product_data$eoq.max),sum(copt_sol$solution)),so.df)
rownames(so.df)<- c("Non Constrained","Constrained")
colnames(so.df)<-c("sum",c(1:62))
kable(so.df[,1:8], row.names = T, escape = F,format = "pandoc")
```




As seen from the table, with no constraint you tend to order far more than constrained. 

* *JRP*

```{r,echo=FALSE}
#JRP
# lower cost
#q.vec

# looking for m values unconstrained Jo vs constrained JO.
#unconstrained

df<-df[mixedorder((colnames(df)))]


unconst.m<- unlist(df[1,])
unconst.m

#constrained

const.m<- unlist(df2[1,])

k<-0
for (i in 1:62) {
  if(const.m[i]>=unconst.m[i]){
    k<-k+1
  }
}

print(k)


```

in JRP for basic cycle, 47 items has equal or more order frequency when capacitated compared to no capacity constrained. 

```{r,echo=FALSE}
mvals<- data.frame(rbind(unconst.m,const.m))

mvals<-cbind(sum=c(sum(unconst.m),sum(const.m)), mvals)
colnames(mvals)<- c("sum",1:62)
kable(mvals,format = "pandoc")
```
In JRP , sum of constrained and unconstrained values and there order frequency values

```{r,echo=FALSE}
unconst.q <- unconst.m*B.int*product_data$demand_per_year

const.q <- product_data$Lot_size_q
  


k<-0
for (i in 1:62) {
  if(const.q[i]<unconst.q[i]){
    k<-k+1
  }
}

print(k)

```

for the quantities of all 62 items , unconstrained is greater than constrained

```{r,echo=FALSE}
qvals<- data.frame(rbind(round(unconst.q),round(const.q)))

qvals<-cbind(sum=c(sum(unconst.q),sum(const.q)), qvals)
colnames(qvals)<- c("sum",1:62)
kable(qvals,format = "pandoc")

```


