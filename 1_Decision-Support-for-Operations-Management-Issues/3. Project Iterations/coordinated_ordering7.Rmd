---
title: "coordinated_ordering7"
author: "GroupB"
date: "11/07/2020"
output: html_document
---

# Data preparation 

```{r setup, include=TRUE, cache=F}
library(readxl)
#setwd("C:\\Users\\Thomas\\Documents\\Thomas\\Owncloud\\Data_Science_PL\\datasets\\coordinated ordering\\Code_group")
product_data <- read_excel("Data_ordering.xlsx",sheet = "product data")
box_data <- read_excel("Data_ordering.xlsx",sheet = "box data")
#rack data
Total_racks=8
levels_per_rack=4
rack_length= 6000
rack_width=1750
rack_height=300

product_data$demand_per_year= ceiling((product_data$`demand per day` *262)/ product_data$`pieces/box`) 

product_data$box_cost= product_data$`pieces/box` * product_data$price

product_data

# shortcut ordering cost

product_data <- merge(product_data, box_data[,c("box ID", "ordering cost (€)")], by = "box ID")

colnames(product_data)[8] <- "ordering_cost"

# order_cost <- double(length(product_data$`box ID`))
# 
# for(j in 1: length(box_data$`box ID`)){
#   for (k in 1:length(product_data$`box ID`)) {
#     if(box_data$`box ID`[j]==product_data$`box ID`[k]){
#       order_cost[k] <- box_data$`ordering cost (€)`[j]
#     }
#   }
#   
# }
# 
# product_data$ordering_cost <- order_cost 
# product_data
```





# EOQ modelling


```{r, cache=TRUE}
#dei= demand_per_year, cori= ordering cost for box i
#cord= ordering cost, pri= box cost, h= interest rate

# directly vectorized
so_eoq_fun <- Vectorize(function(dei,cori,cord,pri,h){
  eoq<- sqrt((2*dei*(cori+cord))/(pri*h))
  return(eoq)
})

# maximum EOQ provided there is no coordination of ordering cycles (i.e., cord are not shared among parallely ordered items)
vec_so_eoq_fun.max <- so_eoq_fun(dei = product_data$demand_per_year,cori=product_data$ordering_cost,cord=1500,pri=product_data$box_cost,h=0.10)
# minimum EOQ disregarding common ordering cost cord
vec_so_eoq_fun.min <- so_eoq_fun(dei = product_data$demand_per_year,cori=product_data$ordering_cost,cord=0,pri=product_data$box_cost,h=0.10)

product_data$eoq.min <- round(vec_so_eoq_fun.min)
product_data$eoq.max <- round(vec_so_eoq_fun.max)


```


# Lane occupation 
```{r}
# constraints #####################################
# this can be formulated more elegantly, but it works and that suffices
b_sorting <- double(length(product_data$`box ID`)) 
b_not_sorting <-double(length(product_data$`box ID`))

for(j in 1: length(box_data$`box ID`)){
  for (k in 1:length(product_data$`box ID`)) {
    if(box_data$`box ID`[j]==product_data$`box ID`[k]){
      
      if(box_data$sorting[j]=="width"){
        b_sorting[k] <- box_data$width[j]
        b_not_sorting[k]<- box_data$length[j]
        
      }else{
        b_sorting[k] <- box_data$length[j]
        b_not_sorting[k]<- box_data$width[j]
      }
    }
  }
  
}

product_data$b_sorting <- b_sorting 
product_data$b_not_sorting <- b_not_sorting

lane.min <- ceiling(product_data$eoq.min * product_data$b_not_sorting / rack_length)
lane.max <- ceiling(product_data$eoq.max * product_data$b_not_sorting / rack_length)

# total rack width 

rack_total_width <- 51200  #rack_width * 4 * 8

# overflow in mm
sum(lane.min*product_data$b_sorting) - rack_total_width
sum(lane.max*product_data$b_sorting) - rack_total_width
# relative overflow in %
(sum(lane.min*product_data$b_sorting) - rack_total_width)/rack_total_width*100
(sum(lane.max*product_data$b_sorting) - rack_total_width)/rack_total_width*100

```

# Constrained EOQ optimization


```{r, cache=TRUE}

library(ROI)
library(ROI.plugin.alabama)

n <- length(product_data$`material ID`) #number of materials
cori <- product_data$ordering_cost   #ordering cost for each items
cord <-  1500    #ordering cost whenever there is an order
dei <- product_data$demand_per_year
h<-0.10
box_cost <- product_data$box_cost #pri

# objective function --> I dropped the 1500*62 as it is not decision relevant
obj.fun <- function(q, d= dei, c.or = cori, c.h = h*box_cost  ) (sum((dei/q)*c.or)+ sum(c.h*(q/2)))
# benchmarks
obj.fun(product_data$eoq.max)
obj.fun(product_data$eoq.min)
# constraint function --> also contains the ceiling of lanes and a sum was missing
const.fun <- function(q, bns = product_data$b_not_sorting, bs = product_data$b_sorting, rl = rack_length) {
  sum(bs * ceiling( bns * q / rl))
  }

const.fun(product_data$eoq.max)
const.fun(product_data$eoq.min)
# try to figure out a freasible starting solution
const.fun(product_data$eoq.min/10) -  rack_total_width

qopt <- OP(
  objective = F_objective(F=obj.fun ,n=n),
  types = rep("C",n),
  bounds = V_bound(ub= product_data$eoq.min , lb= rep(1, n)),
  constraints = F_constraint(F=const.fun,
                             dir="<=",
                             rhs = rack_total_width)
)

#This shows that minimum EOQ is too big and therefore will not meet the rack space constraint.
const.fun(min(product_data$eoq.max))#366272
const.fun(min(product_data$eoq.max)/8)# 61428  still > 56000
const.fun(min(product_data$eoq.max)/8.7)#52716 < 56000
const.fun(round(min(product_data$eoq.max)/10))# 52716 < 56000
round(min(product_data$eoq.max)/10) #17.3


copt_sol <- ROI_solve(qopt, start = rep(min(product_data$eoq.max)/10,n), solver = "alabama" )
# always check whether the algorithm converged
copt_sol# The objective value is: 1.313873e+05
# solution
copt_sol$solution #vector of optimal Quantity that meets the space constraints and minimizes the Obj function.
round(copt_sol$solution)
copt_sol$objval #131387.3

#########################################
# Now you need to fine tune the results 
# --> there are rounding issues -> exactly determining the lane configuration per shelf level
# --> idea to coping with the common ordering cost

const.fun(copt_sol$solution)#55884
const.fun(round(copt_sol$solution))#55686


obj.fun(copt_sol$solution)#131387.3
obj.fun(round(copt_sol$solution))#132096.3  rounded q values

```


# Joint Ordering (JO)

Using Joint replenishment problem

Assumptions:

- One supplier with outbound storage.
- $i=\{1,...,n\}$ products
- Demand rates: $de_i$
- Stock_holding cost rates: $c_i^{sh}$
- Specific setup costs: $c_i^{or}$
- General setup costs: $c^{-or}$
- Cycle time of product $i$: $T_i$

```{r}
n <- length(product_data$`box ID`)
c.or0 <- cord
c.or <- product_data$ordering_cost
#H.vec <- 0.5 * dei * c.sh
# based on the previous definition, I think this should be the vector of holding cost multipliers
H.vec <- 0.1 * product_data$box_cost * dei * .05

```


## Objective Function with no capacity constraint

- $B=$basic cycle time
- $H_i=0.5 \cdot de_i \cdot c_i^{sh}$
- $H_0=0$  Holding cost multiplier are $H_0 \space and  \space H_i$
- $$C(m_i B)=\sum_{i=0}^n (\frac {c_i^{or}}{m_i \cdot B}+H_i \cdot m_i \cdot B) == \frac {c_o^{or}}{B}+ \sum_{i=1}^n (\frac {c_i^{or}}{m_i \cdot B}+H_i \cdot m_i \cdot B)  \\ subject \space to: \quad \quad \quad \quad \quad \quad \quad \quad \quad  \\ m_i \ge m_0 \quad \forall i >0 \\m_i \in \mathbb N \qquad \forall i   $$

--> an important side note is that the JRP is basically a quite standard EOQ problem which uses the substitution $T_i = \frac{q_i}{y_i}$, i.e., $q_i = T_i \cdot y_i$. Then, you substitute $T_i = m_i \cdot B$ ans result in the JRP (adding the common ordering cost).

```{r}
jrp.obj.fun <- function(m , B, cor, Hvec, cor0) cor0/B + sum(cor/B/m) + sum(Hvec*B*m)
```



- *Cycle Time*

we determine $T_i=\sqrt (\frac {c_i^{or}}{H_i})$ and $T^C=\frac {\sum_{j=0}^{i´} c_j^{or}}{\sum_{j=0}^{i´}H_j}$
```{r}
# calculate cycle times
T.vec <- sqrt(c.or/H.vec)
# order products
reo.id <- order(T.vec)
T.vec <- T.vec[reo.id]
c.or <- c.or[reo.id]
H.vec <- H.vec[reo.id]
```

```{r}
library(kableExtra)
# calculate T^2 and cumu. cost shares
res.mat <- t(cbind(c.or/H.vec,(c.or0 + cumsum(c.or))/cumsum(H.vec)))
df <- data.frame(res.mat)
colnames(df) <- reo.id 
rownames(df) <- c(  "$T_i$" ,"$T^C$"  )
kable(df,"pandoc", row.names = T)
```

```{r}
# identify break
which(res.mat[1,] > res.mat[2,])# break occured after 13
id.comb <- min(which(res.mat[1,] > res.mat[2,])) - 1 #3
id.comb
# calculate B
B <- min(T.vec) #0.01955164
# solution with m - integers #######################
m.vec.int <- round(T.vec/B,0)
#I need to address this
m.vec.int[1:id.comb] <- 1  
# re-optimize B for fixed m.vec
B.int <- sqrt(sum(c.or/m.vec.int)/sum(m.vec.int*H.vec))#0.02014868
# total cost 
c.cost.int <- jrp.obj.fun( m = m.vec.int, B=B.int, cor = c.or,Hvec=H.vec, cor0 = c.or0)#192606
df <- data.frame(rbind(round(T.vec/B,2), round(T.vec/B), m.vec.int))
colnames(df) <- reo.id 
rownames(df) <- c("$m_i=\\frac{T_i}{B}$" ,"$[m_i]$", "$[\\tilde{m}_i]$" )
kable(df,"pandoc", row.names = T)
```

Reoptimizing basic cycle time yields $B=$  $`r round(B.int,2)`$ and the total cost are `r round(c.cost.int,2)` 

The order quantities are given by multiplying the cycle times $T_i$ with demand rates $y_i$, i.e. $q_i = T_i \cdot de_i$ such that

```{r}
dei <- dei[reo.id]
df <- data.frame(rbind( m.vec.int, round(m.vec.int*B, 2), round(m.vec.int*B*dei, 2) ))
colnames(df) <- reo.id 
rownames(df) <- c("$[\\tilde{m}_i]$", "$T_i$", "$q_i$" )
kable(df,"pandoc", row.names = T)
```

--> Now the question is: Is this feasible? --> no:

```{r}
q.vec <- m.vec.int*B*dei
const.fun(q.vec) > rack_total_width
```


## Including capacity constraint


When you try to optimize the JRP directly, without introducing the substitution $T_i = m_i \cdot B$ you need to update the JRP function as follows

```{r}
library(ROI)
jrp.obj.fun2 <- function(Tvec, cor, Hvec, cor0) sum(cor0/Tvec) + sum(cor/Tvec) + sum(Hvec*Tvec)
# you need to initialize the parameters in the objective function --> Tvec is to be optimized over, the rest is given
jrp.obj.fun2 <- function(Tvec, cor=c.or, Hvec = H.vec, cor0 = c.or0) sum(cor0/Tvec) + sum(cor/Tvec) + sum(Hvec*Tvec)

qopt2 <- OP(
  objective = F_objective(F=jrp.obj.fun2 , n=62),
  types = rep("C",n),
  bounds = V_bound(ub= rep(30, 62), lb= rep(.001,62))
) 

jrp.obj.fun2(m.vec.int*B)
jrp.obj.fun2(rep(.00001,62))
jrp.obj.fun2(rep(15,62))
# you don't need Alabama here as there is no constraint. Basically you can also optimize this problem by taking derivatives
copt_sol2 <- ROI_solve(qopt2, start = m.vec.int*B)
copt_sol2

copt_sol2$solution

ceiling(copt_sol2$solution * B * dei) # quantity

```


--> You should  integrate the shelf capacity constraint 
--> I also recommmend to stick with the basic period approach

This is formally defined as 
$$ \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot q_i}{rl} \right \rceil \leq \text{tot_rack_length}$$
Thus, with the substitution above, the left-hand side changes to
$$ \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot T_i \cdot y_i}{rl} \right \rceil = \sum_{i=1}^n b_i \cdot \left\lceil\frac{b^{-1}_i \cdot m_i \cdot B \cdot y_i}{rl} \right \rceil$$

Thus, you can change the constraint function quite easily

```{r}
const.fun2 <- function(m, B = B.start, y= dei, bns = product_data$b_not_sorting, bs = product_data$b_sorting, rl = rack_length) {
  sum(bs * ceiling( bns * m*B*y / rl))
  }
```

Then, you can use the original JRP function and update the model by including the capacity constraint. Therefore I recommend that you fix $B$ to some appropriate value based on the feasible solution above

```{r}
# we reinitialize the vectors
n <- length(product_data$`box ID`)
c.or0 <- cord
c.or <- product_data$ordering_cost
H.vec <- 0.1 * product_data$box_cost * dei * .05


T.feas <- copt_sol$solution/dei
B.start <- min(T.feas)

jrp.obj.fun <- function(m , B = B.start, cor = c.or, Hvec = H.vec, cor0 = c.or0) cor0/B + sum(cor/B/m) + sum(Hvec*B*m)
jrp.obj.fun(m= rep(1, 62))
const.fun2(m= rep(1, 62))

qopt3 <- OP(
  objective = F_objective(F=jrp.obj.fun ,n=n),
  # now integer decision variables
  types = rep("C",n),
  bounds = V_bound(li = 1:n, ui = 1:n, ub= rep(50, n) , lb= rep(1, n)),
  constraints = F_constraint(F=const.fun2,
                             dir="<=",
                             rhs = rack_total_width)
)
# god starting point essential --> m = T.feas/B.start
copt_sol3 <- ROI_solve(qopt3, start = T.feas/B.start , solver = "alabama")

copt_sol3

copt_sol3$solution

jrp.obj.fun(m= copt_sol3$solution)
const.fun2(m= copt_sol3$solution) <= rack_total_width

```

Now you should have some good starting solution. Still you need to round the solution. If standard rounding does not yield a feasible solution, rounding down should:

```{r}
# not feasible
const.fun2(round(copt_sol3$solution)) <= rack_total_width
# feasible
const.fun2(floor(copt_sol3$solution)) <= rack_total_width
# potential starting solution
m.start <- floor(copt_sol3$solution) # multiplier m
q.start <- ceiling(m.start * B.start * dei)   # order quantity q (in boxes, rounded up)


```

Afterwards, you have to find a layout scheme such that a precise shelf layout results.

As you rightly point out you need to calculate the number of lanes $l(q_i)$ required for each product given a certain order quantity $q_i$ (integer number of boxes):

$$l(q_i) =\left\lceil \frac{q_i}{n_i} \right\rceil$$
whereby $n_i$ is the number of boxes per lane dedicated to product $i$. I.e., $$n_i = \left\lfloor \frac{rl}{b_i^{-1}} \right\rfloor$$. Thus, for the solution of the JRP we have:

```{r}
l.start <- ceiling(q.start/floor(rack_length/product_data$b_not_sorting))
l.start
```

Now, these lanes have to be assigned to the levels of the shelves. Therefore, we first need to determine the types of lanes required. The lanes are just described by their width. Due to the safety margins we should round the lane width to full centimeter. I.e., we need to assign lanes with the following widths

```{r}
unique(round(product_data$b_sorting/100)*100)
```
Now comes the tricky part: We have to decide how many lanes of a certain width should be assigned for each level. Luckily, there is only a small number of useful patterns of lanes per level. To be precise there are 9 efficient patterns to arrange these 3 lane types (assuming we use each level exhaustively):

```{r}
patterns <- rbind(
c(8,0,0),
c(0,4,0),
c(0,1,2),
c(2,0,2),
c(6,1,0),
c(4,2,0),
c(2,3,0),
c(3,1,1),
c(1,2,1)
)
colnames(patterns) <- c("200","400","600")

patterns
```

Let $p_{k,j}$ indicate the number of lanes of type $j$ associated to pattern $k$. Now we need to assess the number of lanes per required of each type. As outlined above, we know the number of lanes per product $l(q_i)$, thus we can deduce the demand for lane type $j$ ($ld_j$) by summing up the $l(q_i)$  for each lane type,  i.e., $ld_j = \sum_{i \in P|b_i=j} l(q_i)$:

```{r}
# assign lane width as names
names(l.start) <- round(product_data$b_sorting/100)*100 

# number of items with lane types 200, 400, 600 that is demand for each lane type
ld <- c(sum(l.start[names(l.start) == "200"]),
sum(l.start[names(l.start) == "400"]),
sum(l.start[names(l.start) == "600"]))
ld
```

# Changes made on q

1. We assumed that there are 262 working days for the year 2020 according to https://hr.uiowa.edu/pay/payroll-services/payroll-calendars/working-day-payroll-calendar-2020 


2. rack_total_width which was  56,000 mm, looking at the 9 patterns all of which have 150 mm in waste, meaning  all 32 levels will have 150 mm waste each. Therefor $56,000 - (150 *32) = 51,200$ thereby changing rack total width 51,200.

3. These changes then affects the values of q  for all the 62 items involved.


To fulfill lane demands from the items $ld$ are 15 lanes with with 200, 15 lanes with width 400 and 64 lanes with width 600. To fulfull this demand, only 2 patterns are needed.

```{r}
patterns[3:4,]
```
Assign Patterns

```{r}

fitted.pattern <- patterns[3:4,]
# loop through 32 levels to assign patterns

levels.pattern.mat <- matrix(0,  nrow = 32,ncol = 3)

for (i in 1:32) {
  for (j in 1:3) {
    
  if(i<= 16){
    levels.pattern.mat[i,j] <- t(fitted.pattern[1,j])
  } else {
     levels.pattern.mat[i,j] <- t(fitted.pattern[2,j])
   }
  }
}


levels.pattern.mat

# confirm if lane demand is met.

sum(levels.pattern.mat[1:32,1]) >= sum(ld[1]) #TRUE  for 200
sum(levels.pattern.mat[1:32,2]) >= sum(ld[2]) #TRUE  for 400
sum(levels.pattern.mat[1:32,3]) >= sum(ld[3]) #TRUE  for 600

```

This shows that the assignments are correct.

# Asssign Items to levels

*Still ongoing*

```{r}

#ld <- c(sum(l.start[names(l.start) == "200"]),
#sum(l.start[names(l.start) == "400"]),
#sum(l.start[names(l.start) == "600"]))
#ld


#material
#for (i in 1:62) {
 # if(round(product_data$b_sorting[i]/100)*100 == 200){
  #l.start[names(l.start) == "200"]
  #l.start[names(l.start) == "400"]
  #}
  
#}

```


